{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Neural ODEs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-xab72blOap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import autograd.numpy as np\n",
        "import autograd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.integrate import solve_ivp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhdMfi8PlOax",
        "colab_type": "text"
      },
      "source": [
        "# Считаем sin(0.5) через дифур"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH3TCuqslOa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(t, y):\n",
        "    return [y[1], -y[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kH42Y51lOa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "solution = solve_ivp(f, [0, 0.5], [0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6dJjI8mlObE",
        "colab_type": "code",
        "outputId": "bd759b9f-c752-4756-8428-61a95ca1bb55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "solution.y[:,-1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4794257 , 0.87758156])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_BQG6DAlObM",
        "colab_type": "text"
      },
      "source": [
        "# Классы для моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJrla31PlObO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualF:\n",
        "    def __init__(self, x_dim, param):\n",
        "        self.x_dim = x_dim\n",
        "        self.param_dim = param\n",
        "    \n",
        "    def f(self, x, t, param):\n",
        "        pass\n",
        "        \n",
        "    def grad_x(self, t, param):\n",
        "        def cur_f(x):\n",
        "            return self.f(x, t, param)\n",
        "        return autograd.elementwise_grad(cur_f)\n",
        "    \n",
        "    def grad_param(self, x, t):\n",
        "        def cur_f(param):\n",
        "            return self.f(x, t, param)\n",
        "        return autograd.jacobian(cur_f)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuvB9HK8lObV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearF(ResidualF):\n",
        "    def __init__(self, x_dim):\n",
        "        param_dim = x_dim * (x_dim + 1)\n",
        "        super().__init__(x_dim, param_dim)\n",
        "        \n",
        "    def f(self, x, t, param):\n",
        "        assert(len(x) == self.x_dim)\n",
        "        assert(len(param) == self.param_dim)\n",
        "        \n",
        "        param = param.reshape(self.x_dim, self.x_dim + 1)\n",
        "        x_aug = np.concatenate([x, [1]])\n",
        "        return np.dot(param, x_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTWGTAE_lObb",
        "colab_type": "code",
        "outputId": "40f30997-ff26-47ec-b401-c5d387acab91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "linear = LinearF(2)\n",
        "x = np.asarray([1, 2])\n",
        "t = 3\n",
        "param = np.concatenate([[1, 10, 100], [100, 10, 1]])\n",
        "\n",
        "linear.f(x, t, param)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([121, 121])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrcm-FlElObi",
        "colab_type": "code",
        "outputId": "b84e25f5-1d8a-4884-848f-9fc5a2e108e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "linear.grad_x(t, param)(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([101,  20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVo-vHMqlObp",
        "colab_type": "code",
        "outputId": "5d49660d-c38c-4f5a-b461-efc1939ad571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "linear.grad_param(x, t)(param)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 2, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLB9txvflObv",
        "colab_type": "text"
      },
      "source": [
        "# Оптимзасция с помощью SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71MYOLwMlOby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(f, param, x):\n",
        "    def d_y(t, y):\n",
        "        return f.f(y, t, param)\n",
        "    \n",
        "    return solve_ivp(d_y, [0, 1], x).y[:, -1]\n",
        "    \n",
        "def backward(f, param, x_start, x_pred, d_loss):\n",
        "    def pack(x, a, d_param):\n",
        "        assert len(x) == f.x_dim\n",
        "        assert len(a) == f.x_dim\n",
        "        assert len(d_param) == f.param_dim\n",
        "        return np.concatenate([x, a, d_param])\n",
        "    \n",
        "    def unpack(y):\n",
        "        return y[:f.x_dim], y[f.x_dim : f.x_dim * 2], y[-f.param_dim:]\n",
        "    \n",
        "    def d_y(t, y):\n",
        "        x, a_x, a_param = unpack(y)\n",
        "        return pack(f.f(x, t, param),\n",
        "                - a_x * f.grad_x(t, param)(x),\n",
        "                - np.dot(a_x, f.grad_param(x, t)(param))\n",
        "               )\n",
        "    \n",
        "    y_1 = pack(x_pred, d_loss, np.zeros(f.param_dim))\n",
        "    solution = solve_ivp(d_y, [1, 0], y_1)\n",
        "    \n",
        "    x, a, d_param = unpack(solution.y[:,-1])\n",
        "    return d_param\n",
        "\n",
        "def train(f, param, X, X_expected, iters = 50):\n",
        "    lr = 0.1\n",
        "    for i in range(iters):\n",
        "        losses = []\n",
        "        grads = []\n",
        "        \n",
        "        for x, x_expected in zip(X, X_expected):\n",
        "            x_pred = forward(f, param, x)\n",
        "            d_loss = (x_pred - x_expected)\n",
        "            losses.append(0.5 * d_loss ** 2)\n",
        "            d_param = backward(f, param, x, x_pred, d_loss)\n",
        "            grads.append(d_param)\n",
        "            \n",
        "        print(\"iter \" + str(i))\n",
        "        print(\"average loss: \" + str(np.average(losses)))\n",
        "        print()\n",
        "        ave_grad = np.average(grads, axis=0)\n",
        "        param -= ave_grad * lr "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0F4ukN5lOb6",
        "colab_type": "text"
      },
      "source": [
        "# Обучаем на датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6imxRgolOb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 2\n",
        "\n",
        "linear = LinearF(dim)\n",
        "param = np.random.randn(linear.param_dim)\n",
        "\n",
        "X = [np.random.randn(dim) for _ in range(100)]\n",
        "X_expected = np.asarray([2 * x + np.random.randn(dim) * 0.1 + 1 for x in X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njQmbVeslOcC",
        "colab_type": "code",
        "outputId": "96ce82bf-149f-476f-ed4f-618c32ed3227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(linear, param, X, X_expected)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0\n",
            "average loss: 3.0240618703767255\n",
            "\n",
            "iter 1\n",
            "average loss: 2.1955968688945653\n",
            "\n",
            "iter 2\n",
            "average loss: 1.5320615228292902\n",
            "\n",
            "iter 3\n",
            "average loss: 1.0237704228292706\n",
            "\n",
            "iter 4\n",
            "average loss: 0.6929184793472646\n",
            "\n",
            "iter 5\n",
            "average loss: 0.4929510048101811\n",
            "\n",
            "iter 6\n",
            "average loss: 0.3576535602281513\n",
            "\n",
            "iter 7\n",
            "average loss: 0.25799926739524465\n",
            "\n",
            "iter 8\n",
            "average loss: 0.1834563732665244\n",
            "\n",
            "iter 9\n",
            "average loss: 0.12884215207480826\n",
            "\n",
            "iter 10\n",
            "average loss: 0.09010921517391834\n",
            "\n",
            "iter 11\n",
            "average loss: 0.06338363027191533\n",
            "\n",
            "iter 12\n",
            "average loss: 0.0452119146894416\n",
            "\n",
            "iter 13\n",
            "average loss: 0.03287967128201629\n",
            "\n",
            "iter 14\n",
            "average loss: 0.024453958889918536\n",
            "\n",
            "iter 15\n",
            "average loss: 0.01863556722928673\n",
            "\n",
            "iter 16\n",
            "average loss: 0.014571702760054529\n",
            "\n",
            "iter 17\n",
            "average loss: 0.011703421926321643\n",
            "\n",
            "iter 18\n",
            "average loss: 0.009660639891419472\n",
            "\n",
            "iter 19\n",
            "average loss: 0.008194724188190181\n",
            "\n",
            "iter 20\n",
            "average loss: 0.007136129509751907\n",
            "\n",
            "iter 21\n",
            "average loss: 0.006367659521135751\n",
            "\n",
            "iter 22\n",
            "average loss: 0.005807349588255755\n",
            "\n",
            "iter 23\n",
            "average loss: 0.005397304304522819\n",
            "\n",
            "iter 24\n",
            "average loss: 0.0050962874310457726\n",
            "\n",
            "iter 25\n",
            "average loss: 0.004874721969624391\n",
            "\n",
            "iter 26\n",
            "average loss: 0.0047112676252984275\n",
            "\n",
            "iter 27\n",
            "average loss: 0.004590449530833121\n",
            "\n",
            "iter 28\n",
            "average loss: 0.004500997676997386\n",
            "\n",
            "iter 29\n",
            "average loss: 0.004434674247115543\n",
            "\n",
            "iter 30\n",
            "average loss: 0.004385438728736755\n",
            "\n",
            "iter 31\n",
            "average loss: 0.004348849789579708\n",
            "\n",
            "iter 32\n",
            "average loss: 0.00432163422287555\n",
            "\n",
            "iter 33\n",
            "average loss: 0.004301374804679158\n",
            "\n",
            "iter 34\n",
            "average loss: 0.004286283329310795\n",
            "\n",
            "iter 35\n",
            "average loss: 0.0042750349190802265\n",
            "\n",
            "iter 36\n",
            "average loss: 0.004266646685215883\n",
            "\n",
            "iter 37\n",
            "average loss: 0.004260388623839762\n",
            "\n",
            "iter 38\n",
            "average loss: 0.004255718018548057\n",
            "\n",
            "iter 39\n",
            "average loss: 0.0042522310486778235\n",
            "\n",
            "iter 40\n",
            "average loss: 0.004249627021329461\n",
            "\n",
            "iter 41\n",
            "average loss: 0.004247681891999533\n",
            "\n",
            "iter 42\n",
            "average loss: 0.00424622863440524\n",
            "\n",
            "iter 43\n",
            "average loss: 0.004245142670452412\n",
            "\n",
            "iter 44\n",
            "average loss: 0.0042443310442583804\n",
            "\n",
            "iter 45\n",
            "average loss: 0.004243724370604438\n",
            "\n",
            "iter 46\n",
            "average loss: 0.004243270842193541\n",
            "\n",
            "iter 47\n",
            "average loss: 0.004242931766189974\n",
            "\n",
            "iter 48\n",
            "average loss: 0.004242678237781841\n",
            "\n",
            "iter 49\n",
            "average loss: 0.004242488659830601\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}