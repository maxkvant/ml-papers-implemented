{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Wide NNs of Any Depth.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-xab72blOap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import autograd.numpy as np\n",
        "import autograd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.integrate import solve_ivp\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from scipy.linalg import expm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uEMbNA7wIFZ",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuxSiTHgdH9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "X, y = boston.data, boston.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQgoKxczwMaK",
        "colab_type": "text"
      },
      "source": [
        "# Run baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsJXELnLdKmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_score(gen_model, n_iter=100):\n",
        "  r2_scores = []\n",
        "  for _ in range(n_iter):\n",
        "    X_scaled = MinMaxScaler(feature_range=(-1, 1)).fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
        "    y_pred = gen_model().fit(X_train, y_train).predict(X_test)\n",
        "    r2_scores.append(r2_score(y_test, y_pred))\n",
        "  return  np.quantile(r2_scores, 0.25), np.median(r2_scores, ), np.quantile(r2_scores, 0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCoq7Ml6EB1w",
        "colab_type": "code",
        "outputId": "1430b4ef-3873-4616-d45c-0295c04779fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calc_score(lambda: LinearRegression())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6737992258706963, 0.717742885905629, 0.7425129480542201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GALdc1IyrATM",
        "colab_type": "code",
        "outputId": "eecdce55-b0d5-43c7-f3e0-d744d4857a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calc_score(lambda: Ridge())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6816715411428667, 0.7119669782104736, 0.7455065392763538)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDaUznu6f5nx",
        "colab_type": "code",
        "outputId": "617d7642-e81e-4a84-b873-67dbd20def9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calc_score(lambda: KernelRidge())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6578001821386379, 0.6838283738496159, 0.7201450287008737)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqEfcH4GD4QT",
        "colab_type": "code",
        "outputId": "78cd9834-b9e6-45b8-d8c2-687979c60cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calc_score(lambda: Ridge())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6876811741007891, 0.7272240440190129, 0.7547293167396051)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qagKVE0wGaCg",
        "colab_type": "code",
        "outputId": "7b8f3ec7-3b2c-4389-acaf-cb99bc8a7e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calc_score(lambda: RandomForestRegressor())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8337409585833049, 0.8730538610235477, 0.894126937995729)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMzQo2nWhkOp",
        "colab_type": "code",
        "outputId": "bbb05089-5ddd-4666-c04b-aeded7b551e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def gen_model():\n",
        "  return Pipeline(steps=[('scaler', MinMaxScaler()),\n",
        "                         ('knn', KNeighborsRegressor(n_neighbors=2))\n",
        "                         ])\n",
        "\n",
        "calc_score(gen_model)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7035971593808577, 0.7609061665406363, 0.7888953186685794)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqvULrtp6rrP",
        "colab_type": "text"
      },
      "source": [
        "# Models (linear one is irrelevant)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBWA-qBJowPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelF:\n",
        "  def __init__(self, param):\n",
        "    self.param = param\n",
        "\n",
        "  def f(self, x, param):\n",
        "    pass\n",
        "\n",
        "  def apply(self, x):\n",
        "    return self.f(x, self.param)\n",
        "\n",
        "  def grad(self, x):\n",
        "    def cur_f(param):\n",
        "        return self.f(x, param)\n",
        "    return autograd.grad(cur_f)(self.param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUrFNvp5r8ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearF(ModelF):\n",
        "  def __init__(self, x_dim):\n",
        "    self.x_dim = x_dim \n",
        "    param = np.random.randn(x_dim + 1)\n",
        "    param /= np.linalg.norm(param)\n",
        "    super().__init__(param)\n",
        "\n",
        "  def f(self, x, param):\n",
        "    x = np.concatenate([x, [1]])\n",
        "    return np.dot(x, param)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obT3O20LtEne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = len(X[0])\n",
        "linear_f = LinearF(dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zapk8xh9tSTC",
        "colab_type": "code",
        "outputId": "a08fe972-426a-4184-c7a8-24dd97a79dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "print(X[0])\n",
        "print(linear_f.apply(X[0]))\n",
        "print(linear_f.param)\n",
        "d_param = linear_f.grad(X[0])\n",
        "\n",
        "print(d_param)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
            " 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00]\n",
            "28.752760827946183\n",
            "[ 0.29871499 -0.02710037 -0.37296436 -0.2688844  -0.45728984  0.18251882\n",
            "  0.31629371  0.16386581  0.16446996 -0.24773481  0.02230476  0.20516306\n",
            " -0.06243172 -0.4409114 ]\n",
            "[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
            " 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00 1.000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIhPlHGkjI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NN(ModelF):\n",
        "  def __init__(self, x_dim, hidden_size=100):\n",
        "    self.layer1_shape  = (x_dim + 1, hidden_size)\n",
        "    self.layer2_shape = (hidden_size, 1) \n",
        "\n",
        "    param1 = np.random.randn(*self.layer1_shape) / np.sqrt(np.sum(self.layer1_shape) + 1.)\n",
        "    param2 = np.random.randn(*self.layer2_shape) / np.sqrt(np.sum(self.layer2_shape) + 1.)\n",
        "\n",
        "    param = np.concatenate([param1.reshape(-1), param2.reshape(-1)])\n",
        "    super().__init__(param)\n",
        "\n",
        "\n",
        "  def param_to_layers(self, param):\n",
        "    n1 = np.prod(self.layer1_shape)\n",
        "    n2 = np.prod(self.layer2_shape)\n",
        "    assert len(param) == n1 + n2\n",
        "\n",
        "    param1, param2  = param[:n1], param[n1:]\n",
        "    return param1.reshape(self.layer1_shape), param2.reshape(self.layer2_shape) \n",
        "\n",
        "  def f(self, x, param):\n",
        "    x = np.concatenate([x, [1]])\n",
        "    layer1, layer2 = self.param_to_layers(param)\n",
        "    x = np.dot(x, layer1)\n",
        "    x = np.maximum(x, 0) #relu\n",
        "    x = np.dot(x, layer2)\n",
        "    return np.sum(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55EW19OevT-V",
        "colab_type": "text"
      },
      "source": [
        "# Compute sin(a) and cos(a) by exp(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct3YgyRZWpiA",
        "colab_type": "code",
        "outputId": "df876f3b-bbda-4269-c7fd-32a34be3ff41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "a = 30 / 180 * np.pi\n",
        "expm(np.asarray([[0, -1], [1, 0]]) * a)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.8660254, -0.5      ],\n",
              "       [ 0.5      ,  0.8660254]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIIV6fWkv2wM",
        "colab_type": "text"
      },
      "source": [
        "# Train a regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRjGP5NDjf0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FunctionEstimator:\n",
        "  def __init__(self, model_f, learning_rate):\n",
        "    self.model_f = model_f\n",
        "    self.lr = learning_rate\n",
        "    self.right_vector = None\n",
        "    self.grads = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.right_vector = None\n",
        "\n",
        "    n = len(X)\n",
        "\n",
        "    grads   = self._grads(X)\n",
        "    Theta_0 = np.dot(grads, grads.T)\n",
        "    f0 = self.predict(X)\n",
        "\n",
        "    exp_term = expm(- self.lr * Theta_0)\n",
        "    inv_Theta_0 = np.linalg.inv(Theta_0)\n",
        "    right_vector = np.dot(inv_Theta_0, np.dot(np.eye(n) - exp_term, y)) + \\\n",
        "                   np.dot(inv_Theta_0, np.dot(exp_term, f0))\n",
        "    idd = np.dot(Theta_0, np.linalg.inv(Theta_0))\n",
        "    \n",
        "    self.grads = grads\n",
        "    self.right_vector = right_vector     \n",
        "\n",
        "  def predict(self, X):\n",
        "    def predict_one(x):\n",
        "      if self.right_vector is None:\n",
        "        return self.model_f.apply(x)\n",
        "      return np.dot(self._kernel_value(x), self.right_vector)\n",
        "    \n",
        "    return np.asarray([predict_one(x) for x in X])\n",
        "\n",
        "  def _kernel_value(self, x):\n",
        "    grad_x = self.model_f.grad(x)\n",
        "    return np.dot(grad_x, self.grads.T)\n",
        "\n",
        "  def _grads(self, X):\n",
        "    return np.asarray([self.model_f.grad(x) for x in X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wQAfKBl35RJ",
        "colab_type": "code",
        "outputId": "749436b5-eb88-4351-bfb4-d09d79e84743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "dim = len(X[0])\n",
        "\n",
        "for _ in range(10):\n",
        "  model = FunctionEstimator(NN(dim), learning_rate=1.)\n",
        "  X_scaled = MinMaxScaler(feature_range=(-1, 1))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_scaled.fit_transform(X), y)\n",
        "  y_pred_train_before = model.predict(X_train)\n",
        "  \n",
        "  model.fit(X_train, y_train)\n",
        "  test_score = r2_score(y_test, model.predict(X_test))\n",
        "  train_score  = r2_score(y_train, model.predict(X_train))\n",
        "  print(f\"test_score {test_score} train_score {train_score}\")\n",
        "  print()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_score 0.8612083349489982 train_score 0.89407660928637\n",
            "\n",
            "test_score 0.6657240192655545 train_score 0.9120359617312257\n",
            "\n",
            "test_score 0.7677696529139749 train_score 0.9015817008335495\n",
            "\n",
            "test_score 0.7829043393223697 train_score 0.9239348489240387\n",
            "\n",
            "test_score 0.7625958530181464 train_score 0.9073785590272501\n",
            "\n",
            "test_score 0.8676199008853263 train_score 0.9132523839818919\n",
            "\n",
            "test_score 0.8218143929997738 train_score 0.9142279977303175\n",
            "\n",
            "test_score 0.8788995157644584 train_score 0.8953653401787621\n",
            "\n",
            "test_score 0.8360874766570472 train_score 0.9165525146583021\n",
            "\n",
            "test_score 0.7797886262832017 train_score 0.9274265275008722\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}